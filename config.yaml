# Whisper Voice Auth Configuration

# General settings
development_mode: true
skip_api_validation: false

# API settings
api:
  keys:
    - "your-secret-api-key-here"  # Change in production

# CORS settings
cors:
  origins:
    - "*"  # Restrict in production

# Authentication settings
auth:
  speaker_verification_threshold: 0.75  # Minimum similarity score for verification

# Transcription settings
transcription:
  # Primary: OpenAI Whisper API
  primary_service: "openai"  # "openai" or "local"
  fallback_to_local: true    # Use local whisper if OpenAI fails
  
  # Local Whisper (fallback)
  whisper_model: "base"  # Options: tiny, base, small, medium, large
  language: null  # null for auto-detection, or language code like "en", "ru"

# OpenAI API settings
openai:
  api_key: ""  # Set via environment variable OPENAI_API_KEY
  model: "gpt-4o-transcribe"  # Options: gpt-4o-transcribe, gpt-4o-mini-transcribe, whisper-1
  max_retries: 3
  timeout: 30  # Timeout in seconds
  chunk_size_mb: 20  # For large files, split into chunks (max 25MB for OpenAI)

# Language Model integration
llm:
  api_url: ""  # Set this to your LLM API endpoint
  timeout: 30  # Timeout in seconds

# Hybrid STT settings
hybrid_stt:
  whisper_url: "http://localhost:8000"  # URL of local Whisper service
  remote_api_url: ""  # URL of remote STT API
  min_confidence: 0.85  # Minimum confidence threshold
  min_speaker_match: 0.90  # Minimum speaker match threshold
  timeout_local: 5  # Timeout for local service in seconds
  use_semantic_validation: false  # Whether to use semantic validation
  semantic_model: "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"  # Model for semantic comparison
  semantic_threshold: 0.75  # Minimum semantic similarity to prefer local result
